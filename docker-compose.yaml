version: '3'
services:

  zookeeper:
    image: confluentinc/cp-zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  # reachable on 9092 from the host and on 29092 from inside docker compose
  kafka:
    image: confluentinc/cp-kafka
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - '9092:9092'
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "kafka:29092 ", "--list"]
      interval: 5s
      timeout: 10s
      retries: 5
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: LISTENER_INTERNAL://kafka:29092,LISTENER_EXTERNAL://kafka:9092
      KAFKA_ADVERTISED_LISTENERS: LISTENER_INTERNAL://kafka:29092,LISTENER_EXTERNAL://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_INTERNAL:PLAINTEXT,LISTENER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100

  init-kafka:
    image: confluentinc/cp-kafka
    container_name: init-kafka
    depends_on:
      - kafka
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # For DEV:
      kafka-topics --bootstrap-server kafka:29092 --delete --topic dwd-topic
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka:29092 --list

      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic dwd-topic --replication-factor 1 --partitions 1

      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafka:29092 --list
      "
  # ----------------- #
  # Apache Spark      #
  # ----------------- #
  spark:
    image: docker.io/bitnami/spark:3.3
    container_name: spark
    environment:
      SPARK_MODE: master
      CASSANDRA_PASSWORD: cassandra
    depends_on:
      kafka:
        condition: service_healthy
      cassandra:
        condition: service_healthy
    ports:
      - '8080:8080'
      - '4040:4040'
      - '7077:7077'
    volumes:
      - ./data:/data
      - ./data_aggregation:/src
  spark-worker:
    image: docker.io/bitnami/spark:3.3
    container_name: spark-worker
    depends_on:
      kafka:
        condition: service_healthy
      cassandra:
        condition: service_healthy
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark:7077
      SPARK_WORKER_MEMORY: 4G
      SPARK_EXECUTOR_MEMORY: 4G
      SPARK_WORKER_CORES: 4
      CASSANDRA_PASSWORD: cassandra
    volumes:
      - ./data:/data
      - ./data_aggregation:/src 
  # ----------------- #
  # Producer          #
  # ----------------- #
  producer:
    build: ./data_production
    container_name: producer
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      - KAFKA_LISTENER=kafka:29092
      - STREAMING_SPEED=0.0001
      - STATION_ID=00399
  cassandra:
    build: ./data_storage
    container_name: cassandra
    ports:
      - "9042:9042"
    healthcheck:
      test: "cqlsh -u cassandra -p cassandra -k dwd_weather"
      interval: 15s
      timeout: 10s
      retries: 20
    volumes:
      - /var/lib/cassandra
  presto:
    image: prestodb/presto:0.284
    container_name: presto
    ports:
      - '9000:8080'
    volumes:
      - './db_connector/etc:/opt/presto-server/etc'
  superset:
    build: ./data_visualization
    container_name: superset
    environment:
      - ADMIN_USERNAME=admin
      - ADMIN_EMAIL=admin@superset.com
      - ADMIN_PASSWORD=admin
    ports:
      - '8088:8088'
  grafana:
    image: redash/redash
    container_name: redash
    ports:
      - "5001:5000"
      - "5678:5678"
    