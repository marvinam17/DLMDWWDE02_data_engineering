version: '3'
services:
  # ----------------- #
  # Kafka + Zookeeper #
  # ----------------- #
  zookeeper:
    image: confluentinc/cp-zookeeper
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - backend
  kafka:
    image: confluentinc/cp-kafka
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "kafka:29092 ", "--list"]
      interval: 5s
      timeout: 10s
      retries: 5
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: LISTENER_INTERNAL://kafka:29092,LISTENER_EXTERNAL://kafka:9092
      KAFKA_ADVERTISED_LISTENERS: LISTENER_INTERNAL://kafka:29092,LISTENER_EXTERNAL://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_INTERNAL:PLAINTEXT,LISTENER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
    networks:
      - backend
  init-kafka:
    image: confluentinc/cp-kafka
    container_name: init-kafka
    depends_on:
      - kafka
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka:29092 --list

      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic temperature --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic others --replication-factor 1 --partitions 1  

      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafka:29092 --list
      "
    networks:
      - backend
  # ----------------- #
  #       Spark       #
  # ----------------- #
  spark:
    build: ./data_aggregation
    container_name: spark
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1G
    environment:
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: "no"
      SPARK_SSL_ENABLED: "no"
      SPARK_MODE: master
      CASSANDRA_USER: ${CASSANDRA_USER}
      CASSANDRA_PASSWORD: ${CASSANDRA_PW}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PW: ${POSTGRES_PW}
    depends_on:
      kafka:
        condition: service_healthy
      cassandra:
        condition: service_healthy
      postgres:
        condition: service_started
    volumes:
      - ./data_aggregation/data:/data
      - ./data_aggregation:/src
    command: /bin/sh -c "spark-submit /src/main.py"
    networks:
      - backend
  # ----------------- #
  #      Producer     #
  # ----------------- #
  producer:
    build: ./data_production
    container_name: producer
    depends_on:
      kafka:
        condition: service_healthy
      cassandra:
        condition: service_healthy
      postgres: 
        condition: service_started
    environment:
      KAFKA_LISTENER: kafka:29092
      STREAMING_SPEED: 1.0
      STATION_ID: "00433"
    networks:
      - backend
  # ----------------- #
  #     Cassandra     #
  # ----------------- #
  cassandra:
    build: ./data_storage
    container_name: cassandra
    healthcheck:
      test: "cqlsh -u ${CASSANDRA_USER} -p ${CASSANDRA_PW} -k dwd_weather"
      interval: 10s
      timeout: 5s
      retries: 20
    environment:
      CASSANDRA_USER: ${CASSANDRA_USER}
      CASSANDRA_PASSWORD: ${CASSANDRA_PW}  
      HEAP_NEWSIZE: 128M
      MAX_HEAP_SIZE: 2048M
    volumes:
      - ./data_storage/mount/:/var/lib/cassandra
    restart:
      always
    networks:
      - backend
  # ----------------- #
  #     Postgres      #
  # ----------------- #      
  postgres:
    build: ./data_storage_postgres
    container_name: postgres
    restart: always
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PW}
    volumes:
      - ./data_storage_postgres/mount/:/var/lib/postgresql/data
    networks:
      - backend
  # ----------------- #
  #     PrestoDB      #
  # ----------------- #
  presto:
    image: prestodb/presto:0.285
    container_name: presto
    volumes:
      - './db_connector/etc:/opt/presto-server/etc'
    networks:
      - backend
  # ----------------- #
  #     Superset      #
  # ----------------- #
  superset:
    build: ./data_visualization
    container_name: superset
    environment:
      ADMIN_USERNAME: ${SUPERSET_ADMIN_USERNAME}
      ADMIN_EMAIL: ${SUPERSET_ADMIN_EMAIL}
      ADMIN_PASSWORD: ${SUPERSET_ADMIN_PW}
      ADMIN_FIRSTNAME: ${SUPERSET_ADMIN_FIRSTNAME}
      ADMIN_NAME: ${SUPERSET_ADMIN_NAME}
    ports:
      - '8088:8088'
    volumes:
      - './data_visualization/dashboard:/data'
    networks:
      - backend
  superset-init:
    build: ./data_visualization/init
    container_name: superset-init
    environment:
      ADMIN_USERNAME: ${SUPERSET_ADMIN_USERNAME}
      ADMIN_PASSWORD: ${SUPERSET_ADMIN_PW}
    depends_on:
      superset: 
        condition: service_started
    networks:
      - backend
networks:
  backend:
