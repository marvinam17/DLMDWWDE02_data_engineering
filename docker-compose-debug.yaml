version: '3'
services:
  # ----------------- #
  # Kafka             #
  # ----------------- #
  zookeeper:
    image: confluentinc/cp-zookeeper
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - backend
  kafka:
    image: confluentinc/cp-kafka
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "kafka:29092 ", "--list"]
      interval: 5s
      timeout: 10s
      retries: 5
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: LISTENER_INTERNAL://kafka:29092,LISTENER_EXTERNAL://kafka:9092
      KAFKA_ADVERTISED_LISTENERS: LISTENER_INTERNAL://kafka:29092,LISTENER_EXTERNAL://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_INTERNAL:PLAINTEXT,LISTENER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
    networks:
      - backend

  init-kafka:
    image: confluentinc/cp-kafka
    container_name: init-kafka
    depends_on:
      - kafka
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka:29092 --list

      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic temperature --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:29092 --create --if-not-exists --topic others --replication-factor 1 --partitions 1  

      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafka:29092 --list
      "
    networks:
      - backend
  # ----------------- #
  # Apache Spark      #
  # ----------------- #
  spark:
    build: ./data_aggregation
    container_name: spark
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
    ports:
      - '8080:8080'
      - '4040:4040'
      - '7077:7077'
    environment:
      SPARK_MODE: master
      CASSANDRA_USER: cassandra
      CASSANDRA_PASSWORD: cassandra
    depends_on:
      kafka:
        condition: service_healthy
      cassandra:
        condition: service_healthy
    volumes:
      - ./data_aggregation/data:/data
      - ./data_aggregation:/src
    networks:
      - backend
  spark-worker:
    build: ./data_aggregation
    container_name: spark-worker
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1G
    depends_on:
      kafka:
        condition: service_healthy
      cassandra:
        condition: service_healthy
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark:7077
      SPARK_WORKER_MEMORY: 1G
      SPARK_EXECUTOR_MEMORY: 1G
      SPARK_WORKER_CORES: 2
      CASSANDRA_USER: cassandra
      CASSANDRA_PASSWORD: cassandra
    volumes:
      - ./data_aggregation/data:/data
      - ./data_aggregation:/src 
    networks:
      - backend
  # ----------------- #
  # Producer          #
  # ----------------- #
  producer:
    build: ./data_production
    container_name: producer
    depends_on:
      kafka:
        condition: service_healthy
      cassandra:
        condition: service_healthy
    environment:
      KAFKA_LISTENER: kafka:29092
      STREAMING_SPEED: 1.0
      STATION_ID: "00433"
    networks:
      - backend
  # ----------------- #
  # Cassandra         #
  # ----------------- #
  cassandra:
    build: ./data_storage
    container_name: cassandra
    healthcheck:
      test: "cqlsh -u cassandra -p cassandra -k dwd_weather"
      interval: 15s
      timeout: 10s
      retries: 20
    environment:
      CASSANDRA_USER: ${CASSANDRA_USER}
      CASSANDRA_PASSWORD: ${CASSANDRA_PW}  
      HEAP_NEWSIZE: 128M
      MAX_HEAP_SIZE: 2048M
    volumes:
      - ./data_storage/mount/:/var/lib/cassandra
    restart:
      always
    networks:
      - backend
  postgres:
    build: ./storage
    restart: always
    environment:
      POSTGRES_PASSWORD: postgres
    networks:
      - backend
  # ----------------- #
  # PrestoDB          #
  # ----------------- #
  presto:
    image: prestodb/presto:0.285
    container_name: presto
    volumes:
      - './db_connector/etc:/opt/presto-server/etc'
    networks:
      - backend
  # ----------------- #
  # Apache Superset   #
  # ----------------- #
  superset:
    build: ./data_visualization
    container_name: superset
    environment:
      ADMIN_USERNAME: ${SUPERSET_ADMIN_USERNAME}
      ADMIN_EMAIL: ${SUPERSET_ADMIN_EMAIL}
      ADMIN_PASSWORD: ${SUPERSET_ADMIN_PW}
    ports:
      - '8088:8088'
    volumes:
      - './data_visualization/dashboard:/data'
    networks:
      - backend
networks:
  backend:
